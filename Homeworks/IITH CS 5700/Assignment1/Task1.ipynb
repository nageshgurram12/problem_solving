{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Filter the reviews with the date range : <br />\n",
    "    Start date : 01-01-2013 <br/>\n",
    "    End date : 31-12-2013\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = time.strptime(\"01 01, 2013\", \"%m %d, %Y\")\n",
    "end_date = time.strptime(\"12 31, 2013\", \"%m %d, %Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Data files : </p>\n",
    "<i> 1) reviews_Automotive_5.json.gz  (Category : Automatives) </i> <br/>\n",
    "<i> 2) reviews_Office_Products_5.json.gz (Category: Baby) <i> <br/>\n",
    "<i> 3) reviews_Digital_Music_5.json.gz (Category: Digital Music) </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = \"./data/reviews_Automotive_5.json.gz\"\n",
    "file2 = \"./data/reviews_Office_Products_5.json.gz\"\n",
    "file3 = \"./data/reviews_Digital_Music_5.json.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g = gzip.open(path, 'r')\n",
    "    for l in g:\n",
    "        review = eval(l)\n",
    "        review_date = time.strptime(review[\"reviewTime\"], \"%m %d, %Y\")\n",
    "        if review_date >= start_date and review_date <= end_date:\n",
    "            yield review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "from nltk.tag import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_info(token):\n",
    "    '''\n",
    "    1) Convert to lower case\n",
    "    2) Remove special chars\n",
    "    3) Remove stop words \n",
    "    4) Lemmatize\n",
    "    '''\n",
    "    token_info = { 'EMPTY' : False, 'STOP_WORD' : False, 'POS' : '.', 'WORD' : token, 'LM_WORD' : token}\n",
    "    \n",
    "    token = token.lower()\n",
    "    token = re.sub(r'\\W', '', token)\n",
    "    token.strip()\n",
    "    if token == '':\n",
    "        token_info['EMPTY'] = True\n",
    "        return token_info\n",
    "        \n",
    "    if token in stop_words:\n",
    "        token_info['STOP_WORD'] = True\n",
    "        \n",
    "    (w, pos) = pos_tag([token])[0]\n",
    "    if pos[:2] == 'NN':\n",
    "        token_info['POS'] = 'NOUN'\n",
    "    elif pos[:2] == 'JJ' or pos[:2] == 'RR':\n",
    "        token_info['POS'] = 'ADJ/ADV'\n",
    "     \n",
    "    token_info['WORD'] = token\n",
    "    token_info['LM_WORD'] = lemmatizer.lemmatize(token)\n",
    "    return token_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetch top 20 terms, nouns and adjectives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import nlargest\n",
    "\n",
    "def increment(dictionary, key, by=1):\n",
    "    if key in dictionary:\n",
    "        dictionary[key] += by\n",
    "    else:\n",
    "        dictionary[key] = 1\n",
    "\n",
    "def get_stats(file_path, k=20):\n",
    "    '''\n",
    "    Process the file by tokenizing each review\n",
    "    and get top k terms, nouns and adjectives\n",
    "    '''\n",
    "    term_freq = {'TERM' : {}, 'NOUN' : {}, 'ADJ/ADV' : {}}\n",
    "    review_gen = parse(file_path)\n",
    "    total_reviews = 0\n",
    "    for review in review_gen:\n",
    "        total_reviews += 1\n",
    "        for token in word_tokenize(review[\"reviewText\"]):\n",
    "            token_info = get_term_info(token)\n",
    "            if not(token_info['EMPTY'] or token_info['STOP_WORD']):\n",
    "                increment(term_freq['TERM'], token_info['LM_WORD'])\n",
    "                \n",
    "            if token_info['POS'] == 'NOUN':\n",
    "                increment(term_freq['NOUN'], token_info['WORD'])\n",
    "            elif token_info['POS'] == 'ADJ/ADV':\n",
    "                increment(term_freq['ADJ/ADV'], token_info['WORD'])\n",
    "    \n",
    "    print(\"Total reviews : {}\".format(total_reviews))\n",
    "    topk_stats = {'TERM' : {}, 'NOUN' : {}, 'ADJ/ADV' : {}}\n",
    "    topk_stats['TERM'] = {key : term_freq['TERM'][key] for key in nlargest(k, term_freq['TERM'], key = term_freq['TERM'].get)}\n",
    "    topk_stats['NOUN'] = {key : term_freq['NOUN'][key] for key in nlargest(k, term_freq['NOUN'], key = term_freq['NOUN'].get)}\n",
    "    topk_stats['ADJ/ADV'] = {key : term_freq['ADJ/ADV'][key] for key in nlargest(k, term_freq['ADJ/ADV'], key = term_freq['ADJ/ADV'].get)}\n",
    "    \n",
    "    return topk_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews : 9022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'TERM': {'nt': 4153,\n",
       "  'car': 3499,\n",
       "  'use': 3307,\n",
       "  'one': 3221,\n",
       "  'work': 3002,\n",
       "  'product': 2680,\n",
       "  'good': 2507,\n",
       "  'great': 2496,\n",
       "  'well': 2377,\n",
       "  'like': 2339,\n",
       "  'get': 2180,\n",
       "  'would': 2167,\n",
       "  'used': 2020,\n",
       "  'time': 1898,\n",
       "  'battery': 1734,\n",
       "  'easy': 1632,\n",
       "  'light': 1507,\n",
       "  'make': 1485,\n",
       "  'need': 1411,\n",
       "  'much': 1356},\n",
       " 'NOUN': {'i': 20714,\n",
       "  'nt': 4153,\n",
       "  's': 3666,\n",
       "  'use': 3307,\n",
       "  'car': 2929,\n",
       "  'product': 2103,\n",
       "  'time': 1545,\n",
       "  'works': 1510,\n",
       "  'work': 1492,\n",
       "  'battery': 1409,\n",
       "  'need': 1193,\n",
       "  'price': 1072,\n",
       "  've': 1027,\n",
       "  'bought': 996,\n",
       "  'light': 994,\n",
       "  'water': 970,\n",
       "  'oil': 964,\n",
       "  'quality': 946,\n",
       "  'fit': 908,\n",
       "  'put': 849},\n",
       " 'ADJ/ADV': {'great': 2496,\n",
       "  'good': 2494,\n",
       "  'easy': 1632,\n",
       "  'other': 1381,\n",
       "  'much': 1356,\n",
       "  'little': 1135,\n",
       "  'nice': 1057,\n",
       "  'new': 874,\n",
       "  'small': 708,\n",
       "  'last': 698,\n",
       "  'few': 651,\n",
       "  'best': 634,\n",
       "  'most': 596,\n",
       "  'old': 596,\n",
       "  'same': 580,\n",
       "  'many': 542,\n",
       "  'black': 516,\n",
       "  'high': 451,\n",
       "  'hard': 437,\n",
       "  'different': 418}}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stats(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews : 12391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'TERM': {'nt': 10323,\n",
       "  'printer': 9048,\n",
       "  'use': 7827,\n",
       "  'one': 7342,\n",
       "  'paper': 6266,\n",
       "  'like': 6026,\n",
       "  'work': 5061,\n",
       "  'would': 5003,\n",
       "  'ink': 4915,\n",
       "  'pen': 4721,\n",
       "  'great': 4611,\n",
       "  'print': 4546,\n",
       "  'good': 4490,\n",
       "  'well': 4312,\n",
       "  'get': 3995,\n",
       "  'color': 3964,\n",
       "  'need': 3866,\n",
       "  'time': 3834,\n",
       "  'also': 3683,\n",
       "  'easy': 3679},\n",
       " 'NOUN': {'i': 47074,\n",
       "  'nt': 10323,\n",
       "  's': 9508,\n",
       "  'use': 7827,\n",
       "  'printer': 7657,\n",
       "  'paper': 5514,\n",
       "  'ink': 4578,\n",
       "  'print': 3447,\n",
       "  'quality': 3267,\n",
       "  'time': 3217,\n",
       "  'tape': 3204,\n",
       "  'need': 3079,\n",
       "  'work': 2840,\n",
       "  've': 2752,\n",
       "  'price': 2603,\n",
       "  'color': 2458,\n",
       "  'm': 2418,\n",
       "  'pens': 2398,\n",
       "  'product': 2363,\n",
       "  'printing': 2306},\n",
       " 'ADJ/ADV': {'great': 4611,\n",
       "  'good': 4471,\n",
       "  'easy': 3679,\n",
       "  'other': 3335,\n",
       "  'much': 3059,\n",
       "  'nice': 2642,\n",
       "  'little': 2586,\n",
       "  'small': 2004,\n",
       "  'most': 1767,\n",
       "  'black': 1626,\n",
       "  'many': 1492,\n",
       "  'few': 1447,\n",
       "  'old': 1227,\n",
       "  'same': 1210,\n",
       "  'new': 1189,\n",
       "  'last': 1153,\n",
       "  'big': 1143,\n",
       "  'scan': 1120,\n",
       "  'best': 1107,\n",
       "  'different': 1107}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stats(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews : 4589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'TERM': {'song': 6391,\n",
       "  'album': 6129,\n",
       "  'nt': 2884,\n",
       "  'like': 2860,\n",
       "  'one': 2689,\n",
       "  'music': 2326,\n",
       "  'love': 1944,\n",
       "  'great': 1915,\n",
       "  '34': 1884,\n",
       "  'sound': 1791,\n",
       "  'track': 1763,\n",
       "  'good': 1729,\n",
       "  'band': 1594,\n",
       "  'time': 1512,\n",
       "  'cd': 1459,\n",
       "  'really': 1278,\n",
       "  'get': 1121,\n",
       "  'would': 1118,\n",
       "  'best': 1115,\n",
       "  'first': 1114},\n",
       " 'NOUN': {'i': 10537,\n",
       "  's': 6410,\n",
       "  'album': 5286,\n",
       "  'song': 3947,\n",
       "  'nt': 2884,\n",
       "  'songs': 2444,\n",
       "  'music': 2326,\n",
       "  'love': 1882,\n",
       "  'cd': 1367,\n",
       "  'band': 1350,\n",
       "  'sound': 1218,\n",
       "  'time': 1210,\n",
       "  'track': 967,\n",
       "  'albums': 843,\n",
       "  'rock': 841,\n",
       "  'listen': 820,\n",
       "  'tracks': 796,\n",
       "  'm': 736,\n",
       "  'lyrics': 691,\n",
       "  'way': 688},\n",
       " 'ADJ/ADV': {'great': 1913,\n",
       "  'good': 1721,\n",
       "  'best': 1114,\n",
       "  'new': 907,\n",
       "  'much': 894,\n",
       "  'most': 882,\n",
       "  'other': 847,\n",
       "  'many': 571,\n",
       "  'little': 506,\n",
       "  'classic': 467,\n",
       "  'few': 436,\n",
       "  'last': 411,\n",
       "  'same': 404,\n",
       "  'live': 391,\n",
       "  'such': 386,\n",
       "  'single': 368,\n",
       "  'original': 365,\n",
       "  'own': 364,\n",
       "  'hard': 361,\n",
       "  'nice': 358}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stats(file3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
