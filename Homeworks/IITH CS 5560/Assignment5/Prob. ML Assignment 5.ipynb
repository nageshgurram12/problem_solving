{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image classification with different classifiers:\n",
    "\n",
    "Data source : https://archive.ics.uci.edu/ml/datasets/Image+Segmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_data = pd.read_csv(\"segmentation.data\", index_col=None)\n",
    "\n",
    "classes_series = ip_data.iloc[:, 0]\n",
    "classes = classes_series.unique()\n",
    "(total_samples, total_features) = ip_data.shape\n",
    "total_features = total_features-1\n",
    "total_classes = classes.size\n",
    "class_column = 'IMAGE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "x = ip_data.iloc[:, 1:].values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = preprocessing.scale(x) #min_max_scaler.fit_transform(x)\n",
    "ip_data.iloc[:, 1:] = x_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Gaussian Discriminant \n",
    "\n",
    "#### For each class compute the parameters using MLE :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_priors = np.array(total_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets model the class priors using multinouli distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CEMENT       0.142857\n",
       "BRICKFACE    0.142857\n",
       "GRASS        0.142857\n",
       "PATH         0.142857\n",
       "WINDOW       0.142857\n",
       "FOLIAGE      0.142857\n",
       "SKY          0.142857\n",
       "Name: IMAGE, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_counts = classes_series.value_counts()\n",
    "class_priors = classes_counts/total_samples\n",
    "class_priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For each class, model class conditional densities p(x/y=c) with gaussian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccd_mean = ip_data.groupby([class_column]).mean() # np.array((total_classes, total_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccd_cov = ip_data.groupby([class_column]).cov() #np.array((total_classes, total_features, total_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now test for a sample and predict output based on max value among all classes :\n",
    "As class priors are same, we can ignore this term while calculating p(y=c/x), \n",
    "\n",
    "y_hat = argmax p(y=c_i/x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"segmentation.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 14.285714285714286%\n"
     ]
    }
   ],
   "source": [
    "accurate_predictions = 0\n",
    "def predict_accuracy(test_sample):\n",
    "    global accurate_predictions\n",
    "    test_cls = test_sample.loc[class_column]\n",
    "    test_features = test_sample.drop(class_column)\n",
    "    min_cls_posterior = np.inf\n",
    "    predicted_cls = classes[0]\n",
    "    for cls in classes:\n",
    "        # Get mean and covariance for this class\n",
    "        cls_mean = ccd_mean.loc[cls]\n",
    "        cls_cov = ccd_cov.loc[cls]\n",
    "        # take log of exponential term of MVN\n",
    "        exp_term = np.dot(np.dot((test_features - cls_mean).T, np.linalg.pinv(cls_cov)), (test_features - cls_mean))\n",
    "        # Instead of taking det of co-variance, take 1/det(psuedo inverse)\n",
    "        det_inv_cov_term = np.absolute(np.linalg.det(np.linalg.pinv(cls_cov)))\n",
    "        if det_inv_cov_term == 0:\n",
    "            cls_posterior = exp_term\n",
    "        else:\n",
    "            cls_posterior = np.log(det_inv_cov_term) * exp_term\n",
    "        if cls_posterior <= min_cls_posterior:\n",
    "            min_cls_posterior = cls_posterior\n",
    "            predicted_cls = cls\n",
    "    \n",
    "    # if predicted class is same as test sample then increment predictions count\n",
    "    if predicted_cls == test_cls:\n",
    "        accurate_predictions += 1\n",
    "\n",
    "test_data.apply(predict_accuracy, axis=1)\n",
    "print(\"Accuracy : \" + str(accurate_predictions*100/test_data.shape[0]) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Naive Bayes Classifier:\n",
    " \n",
    " #### Consider every feature as univariate gaussian and all are independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1) Get mean & variance for each class and for each feature\n",
    "features = ip_data.columns[1:]\n",
    "features_classes_mean = ip_data.groupby([class_column]).mean().T\n",
    "features_classes_var = ip_data.groupby([class_column]).var().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 16.476190476190474%\n"
     ]
    }
   ],
   "source": [
    "accurate_predictions = 0\n",
    "def predict_accuracy_naive_bayes(test_sample):\n",
    "    global accurate_predictions\n",
    "    test_cls = test_sample.loc[class_column]\n",
    "    test_features = test_sample.drop(class_column)\n",
    "    min_cls_posterior = np.inf\n",
    "    predicted_cls = classes[0]\n",
    "    for cls in classes:\n",
    "        cls_posterior = 1\n",
    "        for feature in features:\n",
    "            fc_mean = features_classes_mean.loc[feature, cls]\n",
    "            fc_var = features_classes_var.loc[feature, cls]\n",
    "            if fc_var == 0:\n",
    "                continue\n",
    "            f_value = test_features.loc[feature]\n",
    "            cls_posterior *= ((f_value-fc_mean)/fc_var) + np.log(np.sqrt(fc_var))\n",
    "        \n",
    "        if cls_posterior <= min_cls_posterior:\n",
    "            min_cls_posterior = cls_posterior\n",
    "            predicted_cls = cls\n",
    "        \n",
    "    if predicted_cls == test_cls:\n",
    "        accurate_predictions += 1\n",
    "\n",
    "test_data.apply(predict_accuracy_naive_bayes, axis=1)\n",
    "print(\"Accuracy : \" + str(accurate_predictions*100/test_data.shape[0]) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression (using liblinear package):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liblinearutil import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 2.80952% (59/2100) (classification)\n"
     ]
    }
   ],
   "source": [
    "lib_ip_classes = pd.factorize(ip_data.iloc[:,0])[0]\n",
    "lib_ip_features = ip_data.iloc[:, 1:]\n",
    "prob = problem(lib_ip_classes, lib_ip_features.values)\n",
    "param = parameter('-s 0 -B 1 -c 4') # c is set to 4 by using -C option already\n",
    "m = train(prob, param)\n",
    "\n",
    "p_labels, p_acc, p_vals = predict(pd.factorize(test_data.iloc[:,0])[0], test_data.iloc[:,1:].values, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
